1. Uploaded SincNet and found Convoltion step for the processing
2. Run training for SincNet and obtain results from Model
3. Researched into noise cancelation and resulted in new discussion for architecture for system (new architecture is shown in Diagram on github)
4. Initially found noise cancelation open-source ML models but that was dropped after finding a open-sourced speech separtion ML model
5. Playing with speech separtion model code to understand what it does with the wav files
6. update diagram for new architecture
7. Ran white noise in combination with a person's voice
--> Uexpected result: noise was considered the signal and the signal was considered noise
--> Unexpected result: The output signal/noise .wav files came out to twice the length of the inputted signal

To Do:
- run random noise into model and see result
- run my own voice with another voice and observe results
- covert the ML model from MATLAB code to C code
- swap input of ML model from .wav file stored in a location to new input from react native
